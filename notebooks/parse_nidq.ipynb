{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse NIDQ or AP digital file to extract trial information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeextractors as se\n",
    "import spikewidgets as sw\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nidq_file = \"/Users/abuccino/Documents/Data/catalyst/brody/A256_2020_10_07_g0_t0.nidq.bin\"\n",
    "ap_file = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_nidq = se.SpikeGLXRecordingExtractor(nidq_file)\n",
    "fs = rec_nidq.get_sampling_frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events_for_trace(trace, n_bits, lsb):\n",
    "    # get LSB (least significant bit)\n",
    "    trace_int = (trace / lsb).astype(int)\n",
    "    \n",
    "    # extract events\n",
    "    events = {}\n",
    "    channels = np.arange(0, n_bits, dtype=int)\n",
    "    for chan in channels:\n",
    "        chan_bin = 2**chan\n",
    "        bit_mask = np.bitwise_and(trace_int, chan_bin)\n",
    "        high_idxs = (bit_mask == chan_bin).astype(int)\n",
    "        \n",
    "        if len(np.where(high_idxs != 0)[0]) > 0:\n",
    "            events[chan] = {}\n",
    "            rising = np.where(np.diff(high_idxs) > 0)[0]\n",
    "            falling = np.where(np.diff(high_idxs) < 0)[0]  \n",
    "            state = np.array([1] * len(rising) + [-1] * len(falling))\n",
    "\n",
    "            ttl = np.concatenate((rising, falling))\n",
    "            ttl_order = np.argsort(ttl)\n",
    "            ttl = ttl[ttl_order]\n",
    "            state = state[ttl_order]\n",
    "\n",
    "            events[chan]['frames'] = ttl\n",
    "            events[chan]['states'] = state\n",
    "            \n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_event_info_nidq(nidq_file, n_bits=8):\n",
    "    \"\"\"\n",
    "    Parse nidq trace to extract event information\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    nidq_file: Path\n",
    "        Path to nidq.bin file\n",
    "    n_bits: int\n",
    "        Number of bits in digital word (default 8)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    events: dict\n",
    "        Dictionary with channel id as key and a dictionary with\n",
    "        'frames' and 'states' as values\n",
    "    \"\"\"\n",
    "    rec_nidq = se.SpikeGLXRecordingExtractor(nidq_file)\n",
    "    fs = rec_nidq.get_sampling_frequency()\n",
    "    digital_trace = rec_nidq.get_traces()[0] # only one trace\n",
    "    lsb = np.sort(np.unique(digital_trace))[1]\n",
    "    \n",
    "    events = get_events_for_trace(digital_trace, n_bits, lsb)\n",
    "    print(f\"Found events for channels: {list(events.keys())}\")\n",
    "        \n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_event_info_ap(ap_file, n_bits=8, chunk_size=100000):\n",
    "    \"\"\"\n",
    "    Parse ap digital trace (385th trace) to extract event information\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    ap_file: Path\n",
    "        Path to ap.bin file \n",
    "    n_bits: int\n",
    "        Number of bits in digital word (default 8)\n",
    "    chunk_size: int\n",
    "        Chunk size in number of frames\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    events: dict\n",
    "        Dictionary with channel id as key and a dictionary with\n",
    "        'frames' and 'states' as values\n",
    "    \"\"\"\n",
    "    from spikeextractors.extraction_tools import divide_recording_into_time_chunks\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    rec_ap = se.SpikeGLXRecordingExtractor(ap_file)\n",
    "    fs = rec_nidq.get_sampling_frequency()\n",
    "    \n",
    "    digital_trace = rec_ap._raw[-1] # only last trace contains digital input\n",
    "    \n",
    "    # get chunks\n",
    "    num_frames = len(digital_trace)\n",
    "    chunks = divide_recording_into_time_chunks(\n",
    "        num_frames=num_frames,\n",
    "        chunk_size=chunk_size,\n",
    "        padding_size=0\n",
    "    )\n",
    "    n_chunk = len(chunks)\n",
    "\n",
    "    chunks_loop_levels = tqdm(range(n_chunk), ascii=True, desc=\"Extracting digital levels\")\n",
    "    chunks_loop_events = tqdm(range(n_chunk), ascii=True, desc=\"Decoding digital input\")\n",
    "    \n",
    "    events_all = {}\n",
    "    digital_levels = np.array([])\n",
    "    for i in chunks_loop_levels:\n",
    "        chunk = chunks[i]\n",
    "        start_frame = chunk['istart']\n",
    "        end_frame = chunk['iend']\n",
    "        \n",
    "        trace_chunk = digital_trace[start_frame:end_frame]\n",
    "        digital_levels = np.concatenate((digital_levels, np.unique(trace_chunk)))\n",
    "        \n",
    "    lsb = np.sort(np.unique(digital_levels))[1]\n",
    "    \n",
    "    for i in chunks_loop_events:\n",
    "        chunk = chunks[i]\n",
    "        start_frame = chunk['istart']\n",
    "        end_frame = chunk['iend']\n",
    "        trace_chunk = digital_trace[start_frame:end_frame]\n",
    "        events_chunk = get_events_for_trace(trace_chunk, n_bits, lsb)\n",
    "\n",
    "        for chan, events in events_chunk.items():\n",
    "            if chan not in events_all:\n",
    "                events_all[chan] = {\"frames\": np.array([]),\n",
    "                                    \"states\": np.array([])}\n",
    "            current_frames = events_all[chan][\"frames\"]\n",
    "            current_states = events_all[chan][\"states\"]\n",
    "\n",
    "            events_all[chan][\"frames\"] = np.concatenate((current_frames, events[\"frames\"] + start_frame))\n",
    "            events_all[chan][\"states\"] = np.concatenate((current_states, events[\"states\"]))    \n",
    "        \n",
    "    return events_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "events_ap = parse_event_info_ap(ap_file, chunk_size=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_nidq = parse_event_info_nidq(nidq_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ev, values in events_nidq.items():\n",
    "    print(f\"Channel {ev}: {len(values['frames'])} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ev, values in events_ap.items():\n",
    "    print(f\"Channel {ev}: {len(values['frames'])} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_frame = fs*40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "timestamps = rec_nidq.frame_to_time(np.arange(end_frame-1))\n",
    "plt.plot(timestamps, rec_nidq.get_traces(end_frame=end_frame)[0])\n",
    "\n",
    "for event_channel, ttls in events.items():\n",
    "    ttl = ttls[\"frames\"]\n",
    "    states = ttls[\"states\"]\n",
    "    rising = ttl[states==1]\n",
    "    rising_ = rising[rising < end_frame]\n",
    "    for r in rising_:\n",
    "        plt.axvline(timestamps[r], color=f\"C{event_channel}\", ls=\"--\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
